{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25ca220",
   "metadata": {},
   "source": [
    "# Name: Jackson Dawson\n",
    "# Group: 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d996f5",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4290bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/21 13:58:14 WARN Utils: Your hostname, MacBook-Pro-2.local, resolves to a loopback address: 127.0.0.1; using 10.41.254.17 instead (on interface en0)\n",
      "25/11/21 13:58:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/21 13:58:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "vg_df = spark.read.json(\"../../data_samples/Video_Games_SAMPLE.jsonl\", multiLine=False)\n",
    "vg_rdd = vg_df.rdd\n",
    "\n",
    "b_df = spark.read.json(\"../../data_samples/Books_SAMPLE.jsonl\", multiLine=False)\n",
    "b_rdd = b_df.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce026f54",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "**Question:** How does consumer sentiment differ between video-game products and book products?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785455e",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe38642",
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_df = vg_df.withColumn(\"category\", F.lit(\"video_game\"))\n",
    "b_df = b_df.withColumn(\"category\", F.lit(\"book\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30326b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vg_df.union(b_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0214c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length column for analysis\n",
    "df = df.withColumn(\"text_length\", F.length(F.col(\"text\")))\n",
    "df = df.withColumn(\"title_length\", F.length(F.col(\"title\")))\n",
    "\n",
    "rdd = df.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd96e0c",
   "metadata": {},
   "source": [
    "## Side-by-Side Comparison Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9da804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: book\n",
      "  Total Reviews: 50000\n",
      "  Avg Rating: 4.41\n",
      "  Stddev Rating: 1.07\n",
      "  Avg Review Length: 421.19\n",
      "  Stddev Review Length: 722.17\n",
      "  Avg Title Length: 25.29\n",
      "  Avg Helpful Votes: 1.84\n",
      "  Total Helpful Votes: 91850\n",
      "  Verified Purchases: 34746\n",
      "  Avg Images Per Review: 0.03\n",
      "\n",
      "Category: video_game\n",
      "  Total Reviews: 50000\n",
      "  Avg Rating: 4.05\n",
      "  Stddev Rating: 1.43\n",
      "  Avg Review Length: 310.42\n",
      "  Stddev Review Length: 659.13\n",
      "  Avg Title Length: 22.89\n",
      "  Avg Helpful Votes: 1.26\n",
      "  Total Helpful Votes: 63152\n",
      "  Verified Purchases: 43058\n",
      "  Avg Images Per Review: 0.08\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "import math\n",
    "\n",
    "# ---- 1. Map each record into (category, value_dict) ----\n",
    "pair_rdd = rdd.map(lambda row: (\n",
    "    row['category'],\n",
    "    {\n",
    "        \"count\": 1,\n",
    "        \"rating_sum\": row['rating'],\n",
    "        \"rating_sq_sum\": row['rating']**2,\n",
    "        \"text_sum\": row['text_length'],\n",
    "        \"text_sq_sum\": row['text_length']**2,\n",
    "        \"title_sum\": row['title_length'],\n",
    "        \"helpful_sum\": row['helpful_vote'],\n",
    "        \"verified_sum\": 1 if row['verified_purchase'] else 0,\n",
    "        \"image_count_sum\": len(row['images'])\n",
    "    }\n",
    "))\n",
    "\n",
    "# ---- 2. Combine values by category ----\n",
    "def combiner(v):\n",
    "    return v\n",
    "\n",
    "def merger(a, b):\n",
    "    return {\n",
    "        \"count\": a[\"count\"] + b[\"count\"],\n",
    "        \"rating_sum\": a[\"rating_sum\"] + b[\"rating_sum\"],\n",
    "        \"rating_sq_sum\": a[\"rating_sq_sum\"] + b[\"rating_sq_sum\"],\n",
    "        \"text_sum\": a[\"text_sum\"] + b[\"text_sum\"],\n",
    "        \"text_sq_sum\": a[\"text_sq_sum\"] + b[\"text_sq_sum\"],\n",
    "        \"title_sum\": a[\"title_sum\"] + b[\"title_sum\"],\n",
    "        \"helpful_sum\": a[\"helpful_sum\"] + b[\"helpful_sum\"],\n",
    "        \"verified_sum\": a[\"verified_sum\"] + b[\"verified_sum\"],\n",
    "        \"image_count_sum\": a[\"image_count_sum\"] + b[\"image_count_sum\"],\n",
    "    }\n",
    "\n",
    "agg = pair_rdd.combineByKey(combiner, merger, merger)\n",
    "\n",
    "# ---- 3. Compute final statistics ----\n",
    "def finalize(category, m):\n",
    "    n = m[\"count\"]\n",
    "    return Row(\n",
    "        category=category,\n",
    "        total_reviews=n,\n",
    "        avg_rating=m[\"rating_sum\"] / n,\n",
    "        stddev_rating=math.sqrt((m[\"rating_sq_sum\"] / n) - (m[\"rating_sum\"]/n)**2),\n",
    "        avg_review_length=m[\"text_sum\"] / n,\n",
    "        stddev_review_length=math.sqrt((m[\"text_sq_sum\"] / n) - (m[\"text_sum\"]/n)**2),\n",
    "        avg_title_length=m[\"title_sum\"] / n,\n",
    "        avg_helpful_votes=m[\"helpful_sum\"] / n,\n",
    "        total_helpful_votes=m[\"helpful_sum\"],\n",
    "        verified_purchases=m[\"verified_sum\"],\n",
    "        avg_images_per_review=m[\"image_count_sum\"] / n\n",
    "    )\n",
    "\n",
    "final_rdd = agg.map(lambda kv: finalize(kv[0], kv[1]))\n",
    "\n",
    "# ---- 4. Display results from RDD ----\n",
    "results = final_rdd.sortBy(lambda row: row.category).collect()\n",
    "for result in results:\n",
    "    print(f\"\\nCategory: {result.category}\")\n",
    "    print(f\"  Total Reviews: {result.total_reviews}\")\n",
    "    print(f\"  Avg Rating: {result.avg_rating:.2f}\")\n",
    "    print(f\"  Stddev Rating: {result.stddev_rating:.2f}\")\n",
    "    print(f\"  Avg Review Length: {result.avg_review_length:.2f}\")\n",
    "    print(f\"  Stddev Review Length: {result.stddev_review_length:.2f}\")\n",
    "    print(f\"  Avg Title Length: {result.avg_title_length:.2f}\")\n",
    "    print(f\"  Avg Helpful Votes: {result.avg_helpful_votes:.2f}\")\n",
    "    print(f\"  Total Helpful Votes: {result.total_helpful_votes}\")\n",
    "    print(f\"  Verified Purchases: {result.verified_purchases}\")\n",
    "    print(f\"  Avg Images Per Review: {result.avg_images_per_review:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b82d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RATING DISTRIBUTION COMPARISON\n",
      "================================================================================\n",
      "rating     book            video_game     \n",
      "----------------------------------------\n",
      "1.0        2263            6409           \n",
      "2.0        1802            2721           \n",
      "3.0        3566            3585           \n",
      "4.0        7979            6695           \n",
      "5.0        34390           30590          \n",
      "\n",
      "\n",
      "REVIEW LENGTH QUARTILES\n",
      "================================================================================\n",
      "\n",
      "Category: book\n",
      "  Min Length: 1\n",
      "  25th Percentile: 75\n",
      "  Median: 176\n",
      "  75th Percentile: 443\n",
      "  Max Length: 15405\n",
      "\n",
      "Category: video_game\n",
      "  Min Length: 0\n",
      "  25th Percentile: 48\n",
      "  Median: 129\n",
      "  75th Percentile: 307\n",
      "  Max Length: 31302\n",
      "\n",
      "\n",
      "HELPFULNESS STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Category: book\n",
      "  Max Helpful Votes: 3401\n",
      "  Reviews with Helpful Votes: 18157\n",
      "\n",
      "Category: video_game\n",
      "  Max Helpful Votes: 1857\n",
      "  Reviews with Helpful Votes: 12714\n",
      "\n",
      "\n",
      "VERIFIED PURCHASE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Category: book\n",
      "  Total Reviews: 50000\n",
      "  Verified Count: 34746\n",
      "  Verified Percentage: 69.49%\n",
      "\n",
      "Category: video_game\n",
      "  Total Reviews: 50000\n",
      "  Verified Count: 43058\n",
      "  Verified Percentage: 86.12%\n"
     ]
    }
   ],
   "source": [
    "# Additional detailed breakdowns \n",
    "\n",
    "print(\"\\nRATING DISTRIBUTION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "# Map to (category, rating) pairs and count\n",
    "rating_counts = rdd.map(lambda row: ((row['category'], row['rating']), 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .collect()\n",
    "\n",
    "# Organize by rating\n",
    "from collections import defaultdict\n",
    "rating_by_category = defaultdict(lambda: {'book': 0, 'video_game': 0})\n",
    "for (category, rating), count in rating_counts:\n",
    "    rating_by_category[rating][category] = count\n",
    "\n",
    "print(f\"{'rating':<10} {'book':<15} {'video_game':<15}\")\n",
    "print(\"-\" * 40)\n",
    "for rating in sorted(rating_by_category.keys()):\n",
    "    counts = rating_by_category[rating]\n",
    "    print(f\"{rating:<10} {counts['book']:<15} {counts['video_game']:<15}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nREVIEW LENGTH QUARTILES\")\n",
    "print(\"=\"*80)\n",
    "# Group text lengths by category\n",
    "category_lengths = rdd.map(lambda row: (row['category'], row['text_length'])) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(list) \\\n",
    "    .collect()\n",
    "\n",
    "for category, lengths in sorted(category_lengths):\n",
    "    sorted_lengths = sorted(lengths)\n",
    "    n = len(sorted_lengths)\n",
    "    q1_idx = n // 4\n",
    "    q2_idx = n // 2\n",
    "    q3_idx = 3 * n // 4\n",
    "    \n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    print(f\"  Min Length: {min(sorted_lengths)}\")\n",
    "    print(f\"  25th Percentile: {sorted_lengths[q1_idx]}\")\n",
    "    print(f\"  Median: {sorted_lengths[q2_idx]}\")\n",
    "    print(f\"  75th Percentile: {sorted_lengths[q3_idx]}\")\n",
    "    print(f\"  Max Length: {max(sorted_lengths)}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nHELPFULNESS STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "# Calculate helpfulness stats by category\n",
    "helpful_stats = rdd.map(lambda row: (\n",
    "    row['category'],\n",
    "    {\n",
    "        'max_votes': row['helpful_vote'],\n",
    "        'has_votes': 1 if row['helpful_vote'] > 0 else 0\n",
    "    }\n",
    ")).reduceByKey(lambda a, b: {\n",
    "    'max_votes': max(a['max_votes'], b['max_votes']),\n",
    "    'has_votes': a['has_votes'] + b['has_votes']\n",
    "}).collect()\n",
    "\n",
    "for category, stats in sorted(helpful_stats):\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    print(f\"  Max Helpful Votes: {stats['max_votes']}\")\n",
    "    print(f\"  Reviews with Helpful Votes: {stats['has_votes']}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nVERIFIED PURCHASE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "# Calculate verification stats\n",
    "verification = rdd.map(lambda row: (\n",
    "    row['category'],\n",
    "    {\n",
    "        'total': 1,\n",
    "        'verified': 1 if row['verified_purchase'] else 0\n",
    "    }\n",
    ")).reduceByKey(lambda a, b: {\n",
    "    'total': a['total'] + b['total'],\n",
    "    'verified': a['verified'] + b['verified']\n",
    "}).collect()\n",
    "\n",
    "for category, stats in sorted(verification):\n",
    "    percentage = (stats['verified'] / stats['total']) * 100\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    print(f\"  Total Reviews: {stats['total']}\")\n",
    "    print(f\"  Verified Count: {stats['verified']}\")\n",
    "    print(f\"  Verified Percentage: {percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
