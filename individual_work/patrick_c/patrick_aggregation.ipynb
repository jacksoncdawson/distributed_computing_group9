{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618b4a0a",
   "metadata": {},
   "source": [
    "# Task 2 - Uploading Dataset to GCP and Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bda459",
   "metadata": {},
   "source": [
    "## Patrick Crouch\n",
    "## Group 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ce6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import open\n",
    "import json\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df45c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/21 13:59:34 WARN Utils: Your hostname, MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 10.2.89.49 instead (on interface en0)\n",
      "25/11/21 13:59:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/21 13:59:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3e7ad",
   "metadata": {},
   "source": [
    "#### Question: Does the length of a review correlate to the rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6284c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patri/miniconda3/envs/distributed_computing/lib/python3.13/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/patri/miniconda3/envs/distributed_computing/lib/python3.13/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "bucket = \"msds-694-cohort-14-group9/data\"\n",
    "filename = \"Electronics.jsonl\"\n",
    "path = f\"gs://{bucket}/{filename}\"\n",
    "\n",
    "first_5000 = []\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5000:\n",
    "            break\n",
    "        first_5000.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f74ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rdd = sc.parallelize(first_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95088bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "average_review_length_by_rating = {}\n",
    "for i in range(5):\n",
    "    rating = i+1\n",
    "    filtered_rdd = base_rdd.filter(lambda x: int(x['rating']) == rating)\n",
    "    review_lengths = filtered_rdd.map(lambda x: len(x['text']))\n",
    "    average_review_length = review_lengths.reduce(lambda x, y: x+y)/filtered_rdd.count()\n",
    "\n",
    "    average_review_length_by_rating[rating] = round(average_review_length, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffa4065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 313.52, 2: 596.99, 3: 567.52, 4: 598.67, 5: 369.23}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_review_length_by_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b492ad6",
   "metadata": {},
   "source": [
    "It seems that review lengths are shorter for 1 and 5 ratings, and longer for the intermediate ratings. If I were to guess why this discrepancy exists, I would think that people who are rating 2, 3 and 4 are thinking more about their rating that those simply choosing the binary best or worst rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1aaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distributed_computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
